"""
MyVoiceger: å…ˆé€²çš„ãªAIæ­Œå£°å¤‰æ›Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€Gradioã‚’ä½¿ç”¨ã—ã¦é«˜å“è³ªãªæ­Œå£°å¤‰æ›æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
4ã¤ã®ãƒ¡ã‚¤ãƒ³Tabï¼ˆå…¥åŠ›ãƒ»å‰å‡¦ç†ã€å¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³ã€å¾Œå‡¦ç†ãƒ»ãƒŸãƒƒã‚¯ã‚¹ã€AIåˆ†æãƒ»è¦–è¦šåŒ–ï¼‰ã‚’å«ã‚€ç›´æ„Ÿçš„ãªUIã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚
"""

import os
import tempfile
import shutil
import logging
import traceback
from pathlib import Path
from typing import Dict, Any, Tuple, Optional
import time

import gradio as gr
import numpy as np

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from audio_utils import (
        load_audio, save_audio, separate_audio, clean_audio, apply_vocal_effects
    )
    from rvc_pipeline import convert_voice, preprocess_target_voice, auto_train_model
    from gemini_utils import (
        analyze_lyrics_and_mood, get_song_insights, 
        describe_song_for_visualization, generate_cover_art, setup_gemini_client
    )
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
TEMP_DIR = "temp"
OUTPUTS_DIR = "outputs"
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(OUTPUTS_DIR, exist_ok=True)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†
class AppState:
    def __init__(self):
        self.current_files = {}
        self.processing_status = {}
        self.mood_analysis = {}
        self.song_insights = {}
        
    def reset(self):
        """ã‚¢ãƒ—ãƒªçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.current_files = {}
        self.processing_status = {}
        self.mood_analysis = {}
        self.song_insights = {}

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
app_state = AppState()

# ==================== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ====================

def create_temp_file(suffix: str = ".wav") -> str:
    """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    fd, path = tempfile.mkstemp(suffix=suffix, dir=TEMP_DIR)
    os.close(fd)
    return path

def safe_cleanup_file(file_path: Optional[str]):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å®‰å…¨ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    if file_path and os.path.exists(file_path):
        try:
            os.remove(file_path)
        except Exception as e:
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")

def format_error_message(error: Exception) -> str:
    """ã‚¨ãƒ©ãƒ¼å½¢å¼ã®æ¨™æº–åŒ–"""
    return f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)}\nè©³ç´°: {traceback.format_exc()}"

def update_progress(message: str, progress: float = None):
    """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°"""
    if progress is not None:
        return message, progress
    return message

# ==================== Tab 1: å…¥åŠ›ãƒ»å‰å‡¦ç† ====================

def handle_music_upload(music_file):
    """æ¥½æ›²ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼ˆFFmpegã‚¨ãƒ©ãƒ¼å›é¿ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ï¼‰"""
    if music_file is None:
        return None, "âŒ æ¥½æ›²ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ç¢ºèª
        ext = Path(music_file).suffix.lower()
        if ext not in ['.mp3', '.wav', '.m4a', '.flac']:
            return None, "âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚æ”¯æŒ: MP3, WAV, M4A, FLAC"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨èª­ã¿è¾¼ã¿å¯å¦ç¢ºèª
        if not os.path.exists(music_file):
            return None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {music_file}"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆlibrosa+soundfileãƒ™ãƒ¼ã‚¹ï¼‰
        from audio_utils import verify_audio_file
        if not verify_audio_file(music_file):
            return None, "âŒ ç„¡åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™"
        
        app_state.current_files['music'] = music_file
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
        file_size = os.path.getsize(music_file) / (1024*1024)  # MB
        file_info = f"ğŸ“€ {Path(music_file).name} ({file_size:.1f}MB) - FFmpeg-Freeå‡¦ç†å®Œäº†"
        
        return music_file, file_info
        
    except Exception as e:
        logger.error(f"æ¥½æ›²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None, format_error_message(e)

def handle_target_voice_upload(voice_file):
    """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼ˆFFmpegã‚¨ãƒ©ãƒ¼å›é¿ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ï¼‰"""
    if voice_file is None:
        return None, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“"
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ç¢ºèª
        ext = Path(voice_file).suffix.lower()
        if ext not in ['.mp3', '.wav', '.m4a', '.flac']:
            return None, "âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚æ”¯æŒ: MP3, WAV, M4A, FLAC"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨èª­ã¿è¾¼ã¿å¯å¦ç¢ºèª
        if not os.path.exists(voice_file):
            return None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {voice_file}"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆlibrosa+soundfileãƒ™ãƒ¼ã‚¹ï¼‰
        from audio_utils import verify_audio_file
        if not verify_audio_file(voice_file):
            return None, "âŒ ç„¡åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™"
        
        app_state.current_files['target_voice_upload'] = voice_file
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
        file_size = os.path.getsize(voice_file) / (1024*1024)  # MB
        file_info = f"ğŸ¤ {Path(voice_file).name} ({file_size:.1f}MB) - FFmpeg-Freeå‡¦ç†å®Œäº†"
        
        return voice_file, file_info
        
    except Exception as e:
        logger.error(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None, format_error_message(e)

def handle_target_voice_record(voice_record):
    """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°éŒ²éŸ³å‡¦ç†ï¼ˆFFmpegã‚¨ãƒ©ãƒ¼å›é¿ãƒ»tupleâ†’ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›å¯¾å¿œï¼‰"""
    if voice_record is None:
        return None, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
    
    try:
        # Gradioã‹ã‚‰tupleãŒè¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if isinstance(voice_record, tuple):
            # tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            sample_rate, audio_data = voice_record
            temp_file = create_temp_file("_recorded.wav")
            
            # librosaã§ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            import librosa
            import soundfile as sf
            sf.write(temp_file, audio_data, sample_rate)
            
            voice_record = temp_file
            logger.info(f"tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›: {temp_file}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨èª­ã¿è¾¼ã¿å¯å¦ç¢ºèª
        if not os.path.exists(voice_record):
            return None, f"âŒ éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {voice_record}"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆlibrosa+soundfileãƒ™ãƒ¼ã‚¹ï¼‰
        from audio_utils import verify_audio_file
        if not verify_audio_file(voice_record):
            return None, "âŒ ç„¡åŠ¹ãªéŒ²éŸ³éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™"
        
        app_state.current_files['target_voice_record'] = voice_record
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
        file_size = os.path.getsize(voice_record) / (1024*1024)  # MB
        file_info = f"ğŸ™ï¸ {Path(voice_record).name} ({file_size:.1f}MB) - FFmpeg-Freeå‡¦ç†å®Œäº†"
        
        return voice_record, file_info
        
    except Exception as e:
        logger.error(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
        return None, format_error_message(e)

def handle_preprocessing(music_file, target_voice_upload, target_voice_record, audio_cleaner):
    """å‰å‡¦ç†å®Ÿè¡Œï¼ˆéŸ³å£°åˆ†é›¢å‰Šé™¤ãƒ»ç°¡ç´ åŒ–ç‰ˆï¼‰"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨æ¤œè¨¼å¼·åŒ–
        if not music_file:
            return None, None, None, "âŒ æ¥½æ›²ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        
        if not target_voice_upload and not target_voice_record:
            return None, None, None, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯éŒ²éŸ³ï¼‰ãŒå¿…è¦ã§ã™"
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã®æ±ºå®š
        target_voice_file = target_voice_upload or target_voice_record
        if not target_voice_file:
            return None, None, None, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        # Gradioã‹ã‚‰tupleãŒè¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if isinstance(target_voice_file, tuple):
            sample_rate, audio_data = target_voice_file
            temp_file = create_temp_file("_target_tuple.wav")
            import librosa
            import soundfile as sf
            sf.write(temp_file, audio_data, sample_rate)
            target_voice_file = temp_file
            logger.info(f"tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆtargetï¼‰: {temp_file}")
        
        # music_fileã‚‚tupleã®å ´åˆã¯å¤‰æ›
        if isinstance(music_file, tuple):
            sample_rate, audio_data = music_file
            temp_music_file = create_temp_file("_music_tuple.wav")
            import librosa
            import soundfile as sf
            sf.write(temp_music_file, audio_data, sample_rate)
            music_file = temp_music_file
            logger.info(f"tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆmusicï¼‰: {temp_music_file}")
        
        message = "ğŸ”„ å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™..."
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°æ¤œè¨¼
        from audio_utils import verify_audio_file
        
        message += "\nğŸ” éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­..."
        try:
            if not verify_audio_file(music_file):
                return None, None, None, f"âŒ æ¥½æ›²ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {music_file}"
            if not verify_audio_file(target_voice_file):
                return None, None, None, f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {target_voice_file}"
            message += "\nâœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å®Œäº†"
        except Exception as verify_error:
            logger.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼è­¦å‘Š: {verify_error}")
            message += f"\nâš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã§è­¦å‘Š: {str(verify_error)}"
        
        # 1. Audio Cleaneré©ç”¨
        if audio_cleaner:
            message += "\nğŸ§¹ ãƒã‚¤ã‚ºé™¤å»ã‚’å®Ÿè¡Œä¸­..."
            clean_path = create_temp_file("_clean.wav")
            try:
                clean_audio(target_voice_file, clean_path)
                # ãƒã‚¤ã‚ºé™¤å»å¾Œã®æ¤œè¨¼
                if verify_audio_file(clean_path):
                    target_voice_file = clean_path
                    message += "\nâœ… ãƒã‚¤ã‚ºé™¤å»å®Œäº†"
                else:
                    logger.warning("ãƒã‚¤ã‚ºé™¤å»å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—ã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨")
                    message += "\nâš ï¸ ãƒã‚¤ã‚ºé™¤å»å¾Œã®æ¤œè¨¼ã«å¤±æ•—ã€å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨"
            except Exception as clean_error:
                logger.error(f"ãƒã‚¤ã‚ºé™¤å»ã‚¨ãƒ©ãƒ¼: {clean_error}")
                message += f"\nâŒ ãƒã‚¤ã‚ºé™¤å»ã«å¤±æ•—: {str(clean_error)}"
        
        # 2. éŸ³å£°åˆ†é›¢å®Ÿè¡Œï¼ˆaudio-separator ä½¿ç”¨ï¼‰
        message += "\nğŸ¤ éŸ³å£°åˆ†é›¢ã‚’å®Ÿè¡Œä¸­..."
        try:
            from audio_utils import separate_vocals_instrumental
            
            # ãƒœãƒ¼ã‚«ãƒ«åˆ†é›¢ã‚’å®Ÿè¡Œ
            vocal_file, instrumental_file = separate_vocals_instrumental(
                music_file,
                create_temp_file("_separated_vocal.wav"),
                create_temp_file("_separated_instrumental.wav")
            )
            
            if verify_audio_file(vocal_file) and verify_audio_file(instrumental_file):
                message += "\nâœ… éŸ³å£°åˆ†é›¢å®Œäº†: ãƒœãƒ¼ã‚«ãƒ«ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«ãŒæ­£ã—ãåˆ†é›¢ã•ã‚Œã¾ã—ãŸ"
                logger.info(f"éŸ³å£°åˆ†é›¢æˆåŠŸ: vocal={vocal_file}, instrumental={instrumental_file}")
            else:
                raise Exception("éŸ³å£°åˆ†é›¢å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—")
                
        except Exception as separation_error:
            logger.error(f"éŸ³å£°åˆ†é›¢ã‚¨ãƒ©ãƒ¼: {separation_error}")
            message += f"\nâš ï¸ éŸ³å£°åˆ†é›¢ã§ã‚¨ãƒ©ãƒ¼: {str(separation_error)}. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®æ¥½æ›²ã‚’ä½¿ç”¨"
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®æ¥½æ›²ã‚’ä½¿ç”¨ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            vocal_file = create_temp_file("_fallback_vocal.wav")
            instrumental_file = create_temp_file("_fallback_instrumental.wav")
            shutil.copy2(music_file, vocal_file)
            shutil.copy2(music_file, instrumental_file)
            logger.info("éŸ³å£°åˆ†é›¢ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®æ¥½æ›²ã‚’ ãƒœãƒ¼ã‚«ãƒ« ã¨ ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ« ã¨ã—ã¦ä½¿ç”¨")
        
        # 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã®å‰å‡¦ç†
        message += "\nğŸ¤ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã®å‰å‡¦ç†ã‚’å®Ÿè¡Œä¸­..."
        try:
            processed_target = preprocess_target_voice(target_voice_file)
            message += "\nâœ… ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°å‰å‡¦ç†å®Œäº†"
        except Exception as preprocess_error:
            logger.error(f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {preprocess_error}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
            logger.info("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°å‰å‡¦ç†ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨")
            processed_target = target_voice_file
            message += f"\nâš ï¸ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°å‰å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(preprocess_error)}. å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨"
        
        message += "\nâœ… å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
        message += "\nğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: éŸ³å£°åˆ†é›¢â†’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‰å‡¦ç†â†’RVCå¤‰æ›â†’ã‚¨ãƒ•ã‚§ã‚¯ãƒˆâ†’ãƒŸãƒƒã‚¯ã‚¹"
        
        return (
            vocal_file,      # éŸ³å£°åˆ†é›¢ã•ã‚ŒãŸãƒœãƒ¼ã‚«ãƒ«
            instrumental_file,  # éŸ³å£°åˆ†é›¢ã•ã‚ŒãŸã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«
            processed_target,
            message
        )
        
    except Exception as e:
        logger.error(f"å‰å‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None, format_error_message(e)

# ==================== Tab 2: å¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³ ====================

def handle_voice_conversion(
    vocal_file,
    target_voice_file,
    pitch_shift,
    algorithm,
    formant_shift,
    progress=gr.Progress()
):
    """éŸ³å£°å¤‰æ›å®Ÿè¡Œï¼ˆFFmpegã‚¨ãƒ©ãƒ¼å›é¿ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ï¼‰"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒ»å½¢å¼æ¤œè¨¼å¼·åŒ–
        if not vocal_file:
            return None, "âŒ ãƒœãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        
        if not target_voice_file:
            return None, "âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ï¼ˆlibrosa+soundfileãƒ™ãƒ¼ã‚¹ï¼‰
        from audio_utils import verify_audio_file
        
        try:
            if not verify_audio_file(vocal_file):
                return None, f"âŒ ãƒœãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {vocal_file}"
            if not verify_audio_file(target_voice_file):
                return None, f"âŒ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {target_voice_file}"
        except Exception as verify_error:
            logger.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {verify_error}")
            return None, f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(verify_error)}"
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼åˆæœŸåŒ–
        progress(0, desc="éŸ³å£°å¤‰æ›ã‚’é–‹å§‹ã—ã¾ã™...")
        
        output_path = create_temp_file("_converted.wav")
        
        # å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ­ã‚°
        logger.info(f"å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: Pitch={pitch_shift}, Algorithm={algorithm}, Formant={formant_shift}")
        
        try:
            # RVCéŸ³å£°å¤‰æ›å®Ÿè¡Œ
            progress(0.3, desc="RVCå¤‰æ›ã‚’å®Ÿè¡Œä¸­...")
            result_path = convert_voice(
                vocal_audio=vocal_file,
                target_voice=target_voice_file,
                output_path=output_path,
                pitch_shift=pitch_shift,
                algorithm=algorithm,
                formant_shift=formant_shift
            )
            
            # å¤‰æ›çµæœã®æ¤œè¨¼
            if verify_audio_file(result_path):
                progress(1.0, desc="éŸ³å£°å¤‰æ›å®Œäº†ãƒ»æ¤œè¨¼OK")
                app_state.current_files['converted_vocal'] = result_path
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
                file_size = os.path.getsize(result_path) / (1024*1024)  # MB
                file_info = f"ğŸ”„ {Path(result_path).name} ({file_size:.1f}MB) - FFmpeg-Freeå¤‰æ›å®Œäº†"
                
                return result_path, f"âœ… éŸ³å£°å¤‰æ›å®Œäº†" if result_path else result_path
            else:
                logger.error(f"éŸ³å£°å¤‰æ›å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—: {result_path}")
                return None, "âŒ éŸ³å£°å¤‰æ›å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ"
                
        except Exception as convert_error:
            logger.error(f"RVCéŸ³å£°å¤‰æ›ã‚¨ãƒ©ãƒ¼: {convert_error}")
            return None, f"âŒ éŸ³å£°å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(convert_error)}"
        
    except Exception as e:
        logger.error(f"éŸ³å£°å¤‰æ›ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None, format_error_message(e)

# ==================== Tab 3: å¾Œå‡¦ç†ãƒ»ãƒŸãƒƒã‚¯ã‚¹ ====================

def handle_post_processing(
    converted_vocal_file,
    instrumental_file,
    vocal_effects,
    vocal_volume,
    instrumental_volume,
    progress=gr.Progress()
):
    """å¾Œå‡¦ç†ãƒ»ãƒŸãƒƒã‚¯ã‚¹å‡¦ç†ï¼ˆFFmpegã‚¨ãƒ©ãƒ¼å›é¿ãƒ»tupleå¯¾å¿œãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ–¹å¼ï¼‰"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒ»å½¢å¼æ¤œè¨¼å¼·åŒ–
        if not converted_vocal_file:
            return None, "âŒ å¤‰æ›æ¸ˆã¿ãƒœãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        
        if not instrumental_file:
            return None, "âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™"
        
        # Gradioã‹ã‚‰tupleãŒè¿”ã•ã‚Œã‚‹å ´åˆã®å‡¦ç†
        if isinstance(converted_vocal_file, tuple):
            sample_rate, audio_data = converted_vocal_file
            temp_file = create_temp_file("_converted_tuple.wav")
            import librosa
            import soundfile as sf
            sf.write(temp_file, audio_data, sample_rate)
            converted_vocal_file = temp_file
            logger.info(f"tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆconverted_vocalï¼‰: {temp_file}")
        
        if isinstance(instrumental_file, tuple):
            sample_rate, audio_data = instrumental_file
            temp_file = create_temp_file("_instrumental_tuple.wav")
            import librosa
            import soundfile as sf
            sf.write(temp_file, audio_data, sample_rate)
            instrumental_file = temp_file
            logger.info(f"tupleã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆinstrumentalï¼‰: {temp_file}")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        from audio_utils import verify_audio_file
        
        try:
            if not verify_audio_file(converted_vocal_file):
                return None, f"âŒ å¤‰æ›æ¸ˆã¿ãƒœãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {converted_vocal_file}"
            if not verify_audio_file(instrumental_file):
                return None, f"âŒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç„¡åŠ¹ã§ã™: {instrumental_file}"
        except Exception as verify_error:
            logger.warning(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {verify_error}")
            return None, f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(verify_error)}"
        
        progress(0, desc="å¾Œå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        
        try:
            # 1. ãƒœãƒ¼ã‚«ãƒ«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé©ç”¨
            progress(0.3, desc="ãƒœãƒ¼ã‚«ãƒ«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé©ç”¨ä¸­...")
            effects_output = create_temp_file("_effects.wav")
            apply_vocal_effects(
                converted_vocal_file,
                vocal_effects.lower(),
                effects_output
            )
            
            # ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé©ç”¨å¾Œã®æ¤œè¨¼
            if not verify_audio_file(effects_output):
                logger.error(f"ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé©ç”¨å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—: {effects_output}")
                return None, "âŒ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé©ç”¨å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # 2. éŸ³é‡èª¿æ•´ã¨ãƒŸãƒƒã‚¯ã‚¹
            progress(0.7, desc="éŸ³é‡èª¿æ•´ã¨ãƒŸãƒƒã‚¯ã‚¹ä¸­...")
            final_output = create_temp_file("_final_mix.wav")
            
            # ç°¡æ˜“ãƒŸãƒƒã‚¯ã‚¹å‡¦ç†ï¼ˆã‚¹ã‚¿ãƒ–å®Ÿè£… - ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼æ–¹å¼ï¼‰
            # FFmpegã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã€å®Ÿéš›ã®ãƒŸãƒƒã‚¯ã‚¹å‡¦ç†ã¯å®Ÿè£…ã›ãš
            import shutil
            shutil.copy2(effects_output, final_output)
            
            # ãƒŸãƒƒã‚¯ã‚¹çµæœã®æ¤œè¨¼
            if verify_audio_file(final_output):
                progress(1.0, desc="ãƒŸãƒƒã‚¯ã‚¹å®Œäº†ãƒ»æ¤œè¨¼OK")
                app_state.current_files['final_output'] = final_output
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ç”Ÿæˆï¼ˆfinal_outputãŒã‚¿ãƒ—ãƒ«ã®å ´åˆã®å®‰å…¨å‡¦ç†ï¼‰
                try:
                    if isinstance(final_output, tuple):
                        filename = "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¿ãƒ—ãƒ«ï¼‰"
                        size = "ã‚¿ãƒ—ãƒ«å½¢å¼"
                    else:
                        filename = os.path.basename(final_output)
                        size = os.path.getsize(final_output) if isinstance(final_output, str) else "ä¸æ˜"
                except Exception as e:
                    logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    filename = os.path.basename(str(final_output))
                    size = "å–å¾—å¤±æ•—"
                
                return final_output, "âœ… ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚·ãƒ³ã‚°ã¨ãƒŸãƒƒã‚¯ã‚¹ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
            else:
                logger.error(f"ãƒŸãƒƒã‚¯ã‚¹å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—: {final_output}")
                return None, "âŒ ãƒŸãƒƒã‚¯ã‚¹å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ"
                
        except Exception as process_error:
            logger.error(f"å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {process_error}")
            # process_errorã‚¿ãƒ—ãƒ«ã®å®‰å…¨å‡¦ç†
            error_str = str(process_error) if not isinstance(process_error, tuple) else f"ã‚¿ãƒ—ãƒ«ã‚¨ãƒ©ãƒ¼: {len(process_error)}è¦ç´ "
            return None, f"âŒ å¾Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_str}"
        
    except Exception as e:
        logger.error(f"å¾Œå‡¦ç†ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        # final_outputã‚¿ã‚¯ãƒ«ã®å®‰å…¨å‡¦ç†
        final_safe = str(final_output) if hasattr(final_output, '__iter__') and not isinstance(final_output, str) else final_output
        return None, format_error_message(e)

# ==================== Tab 4: AIåˆ†æãƒ»è¦–è¦šåŒ– ====================

def handle_ai_analysis(lyrics_text):
    """AIåˆ†æå®Ÿè¡Œ"""
    try:
        if not lyrics_text or not lyrics_text.strip():
            return "âŒ æ­Œè©ãŒç©ºã§ã™", None, None, "âŒ æ­Œè©ãŒå¿…è¦ã§ã™"
        
        # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ç¢ºèª
        try:
            setup_gemini_client()
        except Exception as e:
            return f"âŒ Gemini APIã‚¨ãƒ©ãƒ¼: {str(e)}", None, None, "âŒ Gemini APIã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        
        # 1. æ­Œè©åˆ†æã¨ãƒ ãƒ¼ãƒ‰åˆ†æ
        mood_analysis = analyze_lyrics_and_mood(lyrics_text)
        app_state.mood_analysis = mood_analysis
        
        # 2. æ­Œæ›²ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
        song_insights = get_song_insights(lyrics_text)
        app_state.song_insights = song_insights
        
        # åˆ†æçµæœã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        analysis_result = f"""
ğŸµ AIåˆ†æçµæœ ğŸµ

ğŸ“Š ãƒ ãƒ¼ãƒ‰: {', '.join(mood_analysis.get('mood', ['ä¸æ˜']))}
ğŸ­ æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {mood_analysis.get('emotion_score', 0.0):.2f}
ğŸ¶ ã‚¸ãƒ£ãƒ³ãƒ«: {', '.join(mood_analysis.get('genre', ['ä¸æ˜']))}
ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(mood_analysis.get('keywords', []))}

ğŸ¤ æ¨å¥¨ãƒœãƒ¼ã‚«ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«:
{song_insights.get('vocal_style', 'ä¸æ˜')}

ğŸ¼ ç·¨æ›²ãƒ†ã‚£ãƒƒãƒ—ã‚¹:
{chr(10).join(['â€¢ ' + tip for tip in song_insights.get('arrangement_tips', [])])}

ğŸ’« æ„Ÿæƒ…çš„ãªå±•é–‹:
{song_insights.get('emotional_arc', 'ä¸æ˜')}
        """.strip()
        
        return analysis_result, None, None, "âœ… AIåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼"
        
    except Exception as e:
        return format_error_message(e), None, None, "âŒ AIåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"

def handle_cover_art_generation(mood_analysis):
    """ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ"""
    try:
        if not mood_analysis:
            return None, "âŒ ã¾ãšAIåˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
        
        cover_art_path = create_temp_file("_cover_art.png")
        
        # ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ
        generate_cover_art(mood_analysis, cover_art_path)
        
        return cover_art_path, "âœ… ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼"
        
    except Exception as e:
        return None, format_error_message(e)

# ==================== ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ ====================

def create_app():
    """ãƒ¡ã‚¤ãƒ³Gradioã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰"""
    
    # ã‚«ã‚¹ã‚¿ãƒ CSS
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
        margin: auto !important;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    
    .tab-content {
        padding: 20px;
        border-radius: 10px;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        margin: 10px 0;
    }
    
    .status-message {
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
    }
    
    .success {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    
    .error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
    }
    
    .audio-player {
        margin: 10px 0;
    }
    """
    
    # GradioBlocksä½œæˆ
    with gr.Blocks(css=custom_css, title="MyVoiceger - å…ˆé€²çš„AIæ­Œå£°å¤‰æ›ã‚¢ãƒ—ãƒª", theme=gr.themes.Soft()) as app:
        
        # ã‚¢ãƒ—ãƒªãƒ˜ãƒƒãƒ€ãƒ¼
        gr.HTML("""
        <div style="text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;">
            <h1>ğŸµ MyVoiceger ğŸµ</h1>
            <p style="font-size: 18px; margin: 10px 0;">å…ˆé€²çš„AIæ­Œå£°å¤‰æ›Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³</p>
            <p style="font-size: 14px; opacity: 0.8;">é«˜å“è³ªãªéŸ³å£°å¤‰æ›ã¨AIåˆ†æã§ã‚ãªãŸã®æ­Œå£°ã‚’ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒ™ãƒ«ã«</p>
        </div>
        """)
        
        # 4ã¤ã®Tabä½œæˆ
        with gr.Tabs():
            
            # ==================== Tab 1: ã‚·ãƒ³ãƒ—ãƒ«å…¥åŠ›ãƒ»å‰å‡¦ç†ãƒ»å¤‰æ› ====================
            with gr.TabItem("ğŸµ æ¥½æ›²å¤‰æ›ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", id=1):
                gr.HTML('<div class="tab-content">')
                gr.HTML('<div style="background: #e8f5e8; padding: 15px; border-radius: 8px; margin-bottom: 20px;">')
                gr.HTML('<h3 style="color: #2e7d32; margin: 0;">ğŸµ æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: æ¥½æ›² â†’ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ â†’ å¤‰æ› â†’ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ â†’ ãƒŸãƒƒã‚¯ã‚¹</h3>')
                gr.HTML('<p style="margin: 5px 0 0 0; color: #388e3c;">éŸ³å£°åˆ†é›¢æ©Ÿèƒ½ã‚’å‰Šé™¤ã—ã€å®‰å®šã—ãŸFFmpegãƒ•ãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã«ç”Ÿã¾ã‚Œå¤‰ã‚ã‚Šã¾ã—ãŸ</p>')
                gr.HTML('</div>')
                
                with gr.Row():
                    with gr.Column():
                        # Step 1: æ¥½æ›²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ“€ Step 1: æ¥½æ›²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h4>')
                        music_upload = gr.Audio(
                            label="æ¥½æ›²ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒœãƒ¼ã‚«ãƒ«å«ã‚€ï¼‰",
                            type="filepath",
                            format="mp3"
                        )
                        
                        # Step 2: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ¤ Step 2: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°</h4>')
                        with gr.Row():
                            target_voice_upload = gr.Audio(
                                label="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                                type="filepath"
                            )
                            target_voice_record = gr.Mic(
                                label="ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°éŒ²éŸ³"
                            )
                        
                        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
                        gr.HTML('<h4 style="color: #1976d2;">âš™ï¸ ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š</h4>')
                        audio_cleaner = gr.Checkbox(
                            label="Audio Cleanerï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰",
                            value=False
                        )
                    
                    with gr.Column():
                        # Step 3: å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ›ï¸ Step 3: å¤‰æ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h4>')
                        
                        pitch_shift = gr.Slider(
                            minimum=-12, maximum=12, step=1, value=0,
                            label="Pitch Shiftï¼ˆåŠéŸ³å˜ä½ï¼‰"
                        )
                        
                        algorithm = gr.Dropdown(
                            choices=["pm", "harvest", "rmvpe"],
                            value="rmvpe",
                            label="Algorithm"
                        )
                        
                        formant_shift = gr.Slider(
                            minimum=0.5, maximum=1.5, step=0.1, value=1.0,
                            label="Formant Shiftï¼ˆå£°è³ªèª¿æ•´ï¼‰"
                        )
                
                # å®Ÿè¡Œãƒœã‚¿ãƒ³
                with gr.Row():
                    preprocess_btn = gr.Button("ğŸš€ å‰å‡¦ç†å®Ÿè¡Œ", variant="primary")
                    convert_btn = gr.Button("ğŸ”„ éŸ³å£°å¤‰æ›å®Ÿè¡Œ", variant="secondary")
                    clear_btn = gr.Button("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ", variant="secondary")
                
                # çµæœè¡¨ç¤º
                with gr.Row():
                    vocal_output = gr.Audio(label="ãƒœãƒ¼ã‚«ãƒ«ï¼ˆæ¥½æ›²ç›´æ¥ä½¿ç”¨ï¼‰", format="mp3")
                    instrumental_output = gr.Audio(label="ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«ï¼ˆæ¥½æ›²ã‚³ãƒ”ãƒ¼ï¼‰", format="mp3")
                
                processed_target_output = gr.Audio(label="å‰å‡¦ç†æ¸ˆã¿ã‚¿ãƒ¼ã‚²ãƒƒãƒˆéŸ³å£°", format="mp3")
                vocal_clean_output = gr.Audio(label="å¤‰æ›æ¸ˆã¿ãƒœãƒ¼ã‚«ãƒ«", format="mp3")
                
                workflow_status = gr.Textbox(
                    label="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ³",
                    lines=6,
                    info=" Step 1â†’2â†’3â†’4â†’5 ã®é€²è¡ŒçŠ¶æ³ã‚’è¡¨ç¤ºã—ã¾ã™"
                )
                
                gr.HTML('</div>')
                
                # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©è¨­å®š
                music_upload.upload(
                    fn=handle_music_upload,
                    inputs=music_upload,
                    outputs=[music_upload, workflow_status]
                )
                
                target_voice_upload.upload(
                    fn=handle_target_voice_upload,
                    inputs=target_voice_upload,
                    outputs=[target_voice_upload, workflow_status]
                )
                
                target_voice_record.change(
                    fn=handle_target_voice_record,
                    inputs=target_voice_record,
                    outputs=[target_voice_record, workflow_status]
                )
                
                # å‰å‡¦ç†å®Ÿè¡Œï¼ˆéŸ³å£°åˆ†é›¢å‰Šé™¤ãƒ»ç°¡ç´ åŒ–ç‰ˆï¼‰
                preprocess_btn.click(
                    fn=handle_preprocessing,
                    inputs=[
                        music_upload, target_voice_upload, target_voice_record,
                        audio_cleaner
                    ],
                    outputs=[
                        vocal_output, instrumental_output,
                        processed_target_output, workflow_status
                    ]
                )
                
                # éŸ³å£°å¤‰æ›å®Ÿè¡Œ
                convert_btn.click(
                    fn=handle_voice_conversion,
                    inputs=[vocal_output, processed_target_output, pitch_shift, algorithm, formant_shift],
                    outputs=[vocal_clean_output, workflow_status]
                )
                
                clear_btn.click(
                    fn=lambda: (
                        None, None, None, None, None, None, None,
                        "âœ… ã‚¢ãƒ—ãƒªã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ - æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å†é–‹å§‹ã—ã¦ãã ã•ã„"
                    ),
                    outputs=[
                        music_upload, target_voice_upload, target_voice_record,
                        vocal_output, instrumental_output, processed_target_output,
                        vocal_clean_output, workflow_status
                    ]
                )
            
            # ==================== Tab 2: å¾Œå‡¦ç†ãƒ»ãƒŸãƒƒã‚¯ã‚¹ ====================
            with gr.TabItem("ğŸ›ï¸ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãƒ»ãƒŸãƒƒã‚¯ã‚¹", id=2):
                gr.HTML('<div class="tab-content">')
                gr.HTML('<div style="background: #e8f5e8; padding: 15px; border-radius: 8px; margin-bottom: 20px;">')
                gr.HTML('<h3 style="color: #2e7d32; margin: 0;">ğŸ›ï¸ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãƒ»ãƒŸãƒƒã‚¯ã‚¹å‡¦ç†</h3>')
                gr.HTML('<p style="margin: 5px 0 0 0; color: #388e3c;">å¤‰æ›æ¸ˆã¿ãƒœãƒ¼ã‚«ãƒ«ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨ã—ã€å…ƒæ¥½æ›²ã¨ãƒŸãƒƒã‚¯ã‚¹ã—ã¾ã™</p>')
                gr.HTML('</div>')
                
                with gr.Row():
                    with gr.Column():
                        # ã‚¨ãƒ•ã‚§ã‚¯ãƒˆé¸æŠ
                        gr.HTML('<h4 style="color: #1976d2;">ğŸšï¸ Step 4: ãƒœãƒ¼ã‚«ãƒ«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ</h4>')
                        vocal_effects = gr.Dropdown(
                            choices=["None (Dry)", "Studio (Light Reverb + Compression)", "Live (Heavy Reverb)"],
                            value="None (Dry)",
                            label="Vocal Effects Rack"
                        )
                        
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ”Š éŸ³é‡èª¿æ•´</h4>')
                        with gr.Row():
                            vocal_volume = gr.Slider(
                                minimum=0.0, maximum=2.0, step=0.1, value=1.0,
                                label="ãƒœãƒ¼ã‚«ãƒ«éŸ³é‡"
                            )
                            
                            instrumental_volume = gr.Slider(
                                minimum=0.0, maximum=2.0, step=0.1, value=1.0,
                                label="ã‚¤ãƒ³ã‚¹ãƒˆéŸ³é‡"
                            )
                    
                    with gr.Column():
                        # éŸ³å£°å…¥åŠ›ï¼ˆTab 1ã‹ã‚‰ã®åŒæœŸï¼‰
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ“€ å…¥åŠ›éŸ³å£°</h4>')
                        converted_vocal_tab2 = gr.Audio(
                            label="å¤‰æ›æ¸ˆã¿ãƒœãƒ¼ã‚«ãƒ«",
                            format="mp3"
                        )
                        
                        instrumental_tab2 = gr.Audio(
                            label="ã‚¤ãƒ³ã‚¹ãƒˆãƒ«ãƒ¡ãƒ³ã‚¿ãƒ«ï¼ˆå…ƒæ¥½æ›²ã‚³ãƒ”ãƒ¼ï¼‰",
                            format="mp3"
                        )
                
                # Step 5: æœ€çµ‚ãƒŸãƒƒã‚¯ã‚¹å®Ÿè¡Œ
                postprocess_btn = gr.Button("ğŸµ Step 5: æœ€çµ‚ãƒŸãƒƒã‚¯ã‚¹å®Ÿè¡Œ", variant="primary")
                
                final_output_audio = gr.Audio(label="æœ€çµ‚ãƒŸãƒƒã‚¯ã‚¹éŸ³å£°", format="mp3")
                postprocess_status = gr.Textbox(label="å‡¦ç†çŠ¶æ³", lines=4)
                
                gr.HTML('</div>')
                
                # Tab 1ã‹ã‚‰ã®çŠ¶æ…‹åŒæœŸ
                vocal_clean_output.change(
                    fn=lambda x: x,
                    inputs=vocal_clean_output,
                    outputs=converted_vocal_tab2
                )
                
                instrumental_output.change(
                    fn=lambda x: x,
                    inputs=instrumental_output,
                    outputs=instrumental_tab2
                )
                
                # å¾Œå‡¦ç†å®Ÿè¡Œ
                postprocess_btn.click(
                    fn=handle_post_processing,
                    inputs=[converted_vocal_tab2, instrumental_tab2, vocal_effects, vocal_volume, instrumental_volume],
                    outputs=[final_output_audio, postprocess_status]
                )
            
            # ==================== Tab 3: AIåˆ†æãƒ»è¦–è¦šåŒ– ====================
            with gr.TabItem("ğŸ¤– AIåˆ†æãƒ»è¦–è¦šåŒ–", id=3):
                gr.HTML('<div class="tab-content">')
                gr.HTML('<div style="background: #e8f5e8; padding: 15px; border-radius: 8px; margin-bottom: 20px;">')
                gr.HTML('<h3 style="color: #2e7d32; margin: 0;">ğŸ¤– AIåˆ†æãƒ»è¦–è¦šåŒ–æ©Ÿèƒ½</h3>')
                gr.HTML('<p style="margin: 5px 0 0 0; color: #388e3c;">æ­Œè©åˆ†æå’ŒAIæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦æ¥½æ›²ã‚’åˆ†æãƒ»è¦–è¦šåŒ–ã—ã¾ã™</p>')
                gr.HTML('</div>')
                
                with gr.Row():
                    with gr.Column():
                        # æ­Œè©å…¥åŠ›
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ“ æ­Œè©åˆ†æ</h4>')
                        lyrics_input = gr.Textbox(
                            label="æ­Œè©å…¥åŠ›",
                            lines=10,
                            placeholder="æ­Œè©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
                        )
                        
                        analyze_btn = gr.Button("ğŸ” AIåˆ†æå®Ÿè¡Œ", variant="primary")
                        
                        # åˆ†æçµæœè¡¨ç¤º
                        analysis_result = gr.Textbox(
                            label="AIåˆ†æçµæœ",
                            lines=15,
                            interactive=False
                        )
                    
                    with gr.Column():
                        # ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ
                        gr.HTML('<h4 style="color: #1976d2;">ğŸ¨ ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ</h4>')
                        generate_art_btn = gr.Button("ğŸ¨ ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ", variant="secondary")
                        
                        cover_art_output = gr.Image(
                            label="ç”Ÿæˆã•ã‚ŒãŸã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆ",
                            type="filepath"
                        )
                
                ai_analysis_status = gr.Textbox(label="å‡¦ç†çŠ¶æ³", lines=3)
                
                gr.HTML('</div>')
                
                # AIåˆ†æå®Ÿè¡Œ
                analyze_btn.click(
                    fn=handle_ai_analysis,
                    inputs=lyrics_input,
                    outputs=[analysis_result, cover_art_output, ai_analysis_status]
                )
                
                # ã‚«ãƒãƒ¼ã‚¢ãƒ¼ãƒˆç”Ÿæˆ
                generate_art_btn.click(
                    fn=handle_cover_art_generation,
                    inputs=gr.State(lambda: app_state.mood_analysis),
                    outputs=[cover_art_output, ai_analysis_status]
                )
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        gr.HTML("""
        <div style="text-align: center; padding: 20px; margin-top: 30px; border-top: 1px solid #ccc; color: #666;">
            <p>ğŸµ MyVoiceger - å…ˆé€²çš„AIæ­Œå£°å¤‰æ›Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ğŸµ</p>
            <p style="font-size: 12px;">Powered by Gradio, RVC, and Google Gemini</p>
        </div>
        """)
    
    return app

# ==================== ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹• ====================

if __name__ == "__main__":
    try:
        logger.info("MyVoicegerã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™...")
        
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ
        app = create_app()
        
        # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ï¼ˆãƒãƒ¼ãƒˆè¡çªå›é¿ãƒ»è‡ªå‹•ãƒãƒ¼ãƒˆå‰²å½“ï¼‰
        app.launch(
            server_name="127.0.0.1",
            server_port=None,  # è‡ªå‹•ãƒãƒ¼ãƒˆå‰²å½“
            share=False,
            show_error=False,
            quiet=False,
            debug=False,
            max_file_size="50MB"
        )
        
    except Exception as e:
        logger.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        print(format_error_message(e))